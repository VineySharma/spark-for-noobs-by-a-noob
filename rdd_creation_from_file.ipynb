{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of an RDD and its creation from a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of an RDD:\n",
    "In Spark, the idea is to split the data into multiple nodes i.e. machines. Resilient Distributed Dataset (RDD) is a representation of this distributed dataset. It is an immutable distributed collection of data. Any action performed on an RDD is transmitted to all the nodes where the action is performed on the respective chunck of data.\n",
    "\n",
    "It facilitates two types of operations which are as follows:\n",
    "1. __Transformation__ : Operations on an RDD such as filter() or map() which yield another RDD. \n",
    "2. __Action__: Operations on an RDD which trigger a computation. The result of this computation is returned to the master node or written into a stable storage system. Examples include count(), first(), take(n) or collect(). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD Creation:\n",
    "\n",
    "There are three methods to create RDDs in Spark. These are as follows:\n",
    "1. `parallelize` method: By invoking this method in the driver program we can create a parallelized collections.\n",
    "2. `textFile` method: This method creates an RDD by reading the URL of a file. It reads the file as a collection of lines. _In this notebook, we will use this method to create an RDD_.\n",
    "3. __Existing RDD__: As mentioned earlier, transformation of an existing RDD also results into an RDD. \n",
    "\n",
    "#### Data:\n",
    "Following __[this](https://github.com/jadianes/spark-py-notebooks)__ excellent tutorial on Spark for Python developers, I too will be using the reduced 10% dataset provided for the KDD'99 competition. This dataset can be downloaded from the __[UCI ML repository](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html)__.  \n",
    "\n",
    "This reduced dataset has about half a million network interactions. The file is provided as a _gzip_ file which will be downloaded locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "f = urllib.urlretrieve (\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\", \"kddcup.data_10_percent.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data from the gzip file. Note that the `textFile` method can read directly from a compressed file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gzip_file = \"./kddcup.data_10_percent.gz\"\n",
    "raw_data = sc.textFile(data_gzip_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the data is loaded correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494021"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of lines in the dataset\n",
    "raw_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.',\n",
       " u'0,tcp,http,SF,239,486,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,19,19,1.00,0.00,0.05,0.00,0.00,0.00,0.00,0.00,normal.',\n",
       " u'0,tcp,http,SF,235,1337,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,29,29,1.00,0.00,0.03,0.00,0.00,0.00,0.00,0.00,normal.',\n",
       " u'0,tcp,http,SF,219,1337,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,6,6,0.00,0.00,0.00,0.00,1.00,0.00,0.00,39,39,1.00,0.00,0.03,0.00,0.00,0.00,0.00,0.00,normal.',\n",
       " u'0,tcp,http,SF,217,2032,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,6,6,0.00,0.00,0.00,0.00,1.00,0.00,0.00,49,49,1.00,0.00,0.02,0.00,0.00,0.00,0.00,0.00,normal.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the first few lines of the dataset\n",
    "raw_data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
